:source-highlighter: pygments
:stem:

= Processamento Digital de Imagens
Filipe Viana <filipeviana_@live.com>; Gusttavo Silva <gust.tavohenrique@hotmail.com>
:toc: left
:toc-title: Sumário

== 1. Introdução

Neste relatório, serão mostrados os códigos de implementação das atividades da disciplina Processamento Digital de Imagens do curso de Engenharia de Computação da Universidade Federal do Rio Grande do Norte (UFRN). Nesse documento, abordaremos sobre o uso da biblioteca openCV (Open Source Computer Vision Library), bastante utilizada na resolução de problemas de tratamento de imagens, visão computacional e reconhecimento de padrões.

Obs.: a compilação de todos os programas presentes nesse relatório é feita juntamente com o programa link:Projetos/Makefile[Makefile].


== 2. Manipulando pixels em uma imagem

=== 2.1 Negativo de uma região da imagem
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios[Ver exercício 3.2.1]

O programa tem como parâmetro o caminho para um arquivo de imagem, que será carregada em um objeto do tipo Mat no formato de tons de cinza.
Uma região retangular dessa imagem, definida pelo usuário através das variaveis P1X, P2X, P1Y e P2Y, terá seus valores negativados, para
isso o valores dos pixels da região selecionada será 255 subtraído por ele mesmo. Dessa forma, a região definida pelo usuário terá tons
de cinza opostos ao original, criando o efeito de negativo.

Abaixo encontra-se o código do programa link:Projetos/regions.cpp[regions.cpp].

[[exa_regions, regions.cpp]]
[source,cpp]
.Listagem 1: regions.cpp
----
#include <iostream>
#include <cv.h>
#include "opencv2/highgui/highgui.hpp" 

/*
    Quatro parametros são entrada para esse programa, Xi, Xf, Yi e Yf, que são
    usado para determinar a região que será negativada. 
*/

using namespace cv;
using namespace std;

int main(int, char** argv){
    Mat img;
    int P1X, P1Y, P2X, P2Y;

    img= imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
    if(!img.data)
       cout << "error - image can't open" << endl;
    
    int xMax = img.rows;
    int yMax = img.cols;
    
    cout << "size (" << xMax << ", " << yMax << ")" << endl;
    
    cout << "Xi = ";
    cin >> P1X;
    cout << "Xf = ";
    cin >> P2X;
    
    cout << "Yi = ";
    cin >> P1Y;
    cout << "Yf = ";
    cin >> P2Y;
    
    for (int i = P1X; i < P2X; i++) {
        for (int j = P1Y; j < P2Y; j++) {
            img.at<uchar>(i,j) = 255 - img.at<uchar>(i,j); // Operação de negativo pixel = 255 - pixel
        }
    }

    namedWindow("window",WINDOW_AUTOSIZE);
    imshow("window", img);
    waitKey();
    return 0;
}
----

Aplicamos o algoritmo informando as entradas (15, 30) e (300, 280) para a imagem <<fig_arara>>. O resultado obtido é mostrado na imagem <<fig_negativo_arara>>.

[[fig_arara, arara.png]]
//[.text-center]
.Imagem original
image::images/arara.png[Imagem original, title="Imagem original"]

[[fig_negativo_arara, negativo_arara.png]]
//[.text-center]
.Imagem processada
image::images/negativo_arara.png[Imagem processada, title="Imagem processada"]

=== 2.2 Trocando regiões de uma imagem
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios[Ver exercício 3.2.2]

O programa <<exa_troca_regions>> tem como parâmetro um caminho para uma imagem, que será então carregada em tons de cinza. Esta imagem será dividida em quatro subregiões que serão embaralhadas, criando um quebra-cabeça, conforme um vetor de índices gerado randomicamente. Para a formação do quebra-cabeça os vetores 'vert', que armazena as coordenadas x e y das 4 subregiões no formato[x0,y0,x1,y2,...],
e o vetor 'vertPuzzle', que contêm a ordem em que as subregiões irão entrar na imagem do quebra-cabeça. A função copyTo(Mat, ROI) foi usada para fazer a cópia da região da imagem original para a nova região, dada pelo vetor 'vertPuzzle', no quebra-cabeça.

link:Projetos/trocaRegioes.cpp[Clique aqui] para obter o código do programa abaixo.

[[exa_troca_regions, trocaRegioes.cpp]]
[source,cpp]
.Listagem 2: trocaRegioes.cpp
----
#include <iostream>
#include <cv.h>
#include "opencv2/highgui/highgui.hpp"
#define NSUBIMAGES 4

#include <stdio.h>
#include <stdlib.h>
#include <time.h>

using namespace cv;
using namespace std;

int main(int, char** argv){
    Mat img;
    Mat newImg;
    
    img = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
    
    if (!img.data) {
        cout << "Image " << argv[1] << " could not be opened";
    }
    
    int imgRows = img.rows;
    int imgCols = img.cols;
    int subImageRows = imgRows/(NSUBIMAGES/2);
    int subImageCols = imgCols/(NSUBIMAGES/2);
    
    vector<int> vert;
    //vector<Mat> subImgs;
    vector<int> vertPuzzle;
    
    cout << "image size: " << imgRows << "x" << imgCols << endl;
    
    cout << "sub image size: " << subImageRows << "x" << subImageCols << endl;
    
    //cria vetor com os pontos de inicio de cada sub imagem
    for (int i =0 ; i < NSUBIMAGES/2; i++) {
        for (int j = 0; j < NSUBIMAGES/2; j++) {
            vert.push_back(i*subImageRows);
            vert.push_back(j*subImageCols);
            cout << "vertice: (" << i*subImageRows << "," << j*subImageCols << ")" << endl;
        }
    }
    
    //cria vetor aleatorio para criacao do quebra cabeca
    while (vertPuzzle.size()<NSUBIMAGES) {
        int temp = rand() % NSUBIMAGES;
        int flag = -1;
        for (int i = 0; i < vertPuzzle.size() ; i++) {
            if (temp == vertPuzzle.at(i)) {
                flag = 1;
            }
        }
        if (flag == -1) {
            vertPuzzle.push_back(temp);
        }
    }
    
    //imprime o vetor de reordenacao na tela
    cout << "vetor de reordenção: ";
    for (int i=0; i< vertPuzzle.size(); i++) {
        cout << vertPuzzle.at(i) << ", ";
    }
    cout << endl;;
    
    
    newImg = img.clone();
    //rotina para copiar uma RIO da imagem original para outra posicao no quebra cabeca
    for (int i = 0; i < NSUBIMAGES; i++) {
        int x = vert.at(2*vertPuzzle.at(i)+1);
        int y = vert.at(2*vertPuzzle.at(i));
	int x0 = vert.at(2*i+1);
        int y0 = vert.at(2*i);
        Mat(img, Rect(x0, y0, subImageCols, subImageRows)).copyTo(Mat(newImg, Rect(x, y, subImageCols,subImageRows)));
    }
    
    namedWindow("PuzzleImage", WINDOW_AUTOSIZE);
    imshow("PuzzleImage", newImg);
    namedWindow("Image", WINDOW_AUTOSIZE);
    imshow("Image", img);
     
    waitKey();
    return 0;
}
----

O resultado do processamento acima na imagem link:images/arara.png[arara.png] está mostrado na imagem abaixo.

[[fig_troca_regions_arara, troca_regions_arara]]
//[.text-center]
.Imagem processada
image::images/troca_regions_arara.png[Imagem processada, title="Imagem processada"]


== 3. Preenchendo regiões

=== 3.1 Contagem de objetos 
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_2[Ver exercício 4.2.1]

Mesmo que o contador seja maior que os 255, só há como o computador representar 255 tons de cinza. Dessa forma, na forma como o programa 
link:Projetos/labeling.cpp[labeling.cpp] está implementado, depois que o contador ultrapassar o nível de cinza 255, todos os objetos que 
passarem pelo processamento do floodFill terão seus níveis de cinza iguais a 255. 

Para a resolução desse problema, reiniciariamos o contador logo que ele passasse por 255. link:Projetos/contagem_objetos.cpp[Clique aqui] 
para obter o código do programa abaixo.

[[exa_contagem_objetos, contagem_objetos.cpp]]
[source,cpp]
.Listagem 3: contagem_objetos.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
    Mat image;
    int width, height;
    int contadorObjetos, tonDeCinza;

    CvPoint p;
    image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);

    if(!image.data){
        std::cout << "imagem nao carregou corretamente\n";
        return(-1);
    }
    width=image.size().width;
    height=image.size().height;

    p.x=0;
    p.y=0;

    // busca objetos com buracos presentes
    tonDeCinza=0;
    contadorObjetos = 0;

    for(int i=0; i<height; i++){
        for(int j=0; j<width; j++){
          if(image.at<uchar>(i,j) == 255){
            // achou um objeto
            tonDeCinza++;
            contadorObjetos++;

            p.x=j;
            p.y=i;
            floodFill(image,p,tonDeCinza);

            if(tonDeCinza >= 255)
                tonDeCinza = 0;
          }
        }
    }

    cout << "Qtd. objetos: " << contadorObjetos << endl;

    imshow("image", image);
    waitKey();

    return 0;
}
----


=== 3.2 Contagem de objetos com ou sem buracos
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_2[Ver exercício 4.2.2]

A solução proposta para esse problema foi a seguinte: antes de tudo, desenhamos um retângulo com nível 
de cinza igual a 255 na borda da imagem. Depois disso, utilizamos a função floodFill no primeiro pixel 
da imagem mudando os valores dos tons dos pixels para zero. Dessa forma, os objetos que estavam em contato
com esse retangulo foram imdediatamente removidos.

Após a remoção dos objetos da borda, alteramos o ton do fundo da imagem para o valor 100.
Os buracos dos objetos continuaram com o ton de cinza 0 e os objetos com 255. Fazendo uma varredura
sequêncial nos pixels da imagem, ao encontrar um pixel com nível de cinza igual a 255, passamos o floodfill
mudando a cor do objeto para 200 e realizando a contagem do mesmo. Caso um pixel com valor igual a 0 fosse encontrado,
alteravamos sua cor para a nova cor de fundo e contabilzavamos um buraco. Para finalizar, passamos novamente
o floodFill no primeiro pixel da imagem para mudar a cor do fundo para 0.

link:Projetos/contagem_buracos.cpp[Clique aqui] para obter o código do programa abaixo.

[[exa_contagem_buracos, contagem_buracos.cpp]]
[source,cpp]
.Listagem 4: contagem_buracos.cpp
----
#include <iostream>
#include <cv.h>
#include "opencv2/highgui/highgui.hpp"
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
    Mat image;
    int width, height;
    const int tonDeCinzaPreto = 0, tonDeCinzaBranco = 255;
    const int novaCorFundo = 100, novaCorObjeto = 200;
    int contadorObjetosSemBuraco, contadorObjetosComBuraco;

    CvPoint p;
    image = imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);

    if(!image.data){
        std::cout << "imagem nao carregou corretamente\n";

        return(-1);
    }

    width = image.size().width;
    height = image.size().height;

    p.x = 0;
    p.y = 0;

    contadorObjetosSemBuraco = 0;
    contadorObjetosComBuraco = 0;

    Mat novaImagem = Mat::ones(width + 2, height + 2, CV_8U)*tonDeCinzaBranco;
    Mat(image, Rect(0, 0, width, height)).copyTo(Mat(novaImagem, Rect(1,1,width, height)));

    floodFill(novaImagem,p,tonDeCinzaPreto);

    floodFill(novaImagem,p,novaCorFundo);

    for(int i=0; i<height; i++){
        for(int j=0; j<width; j++){
            if(novaImagem.at<uchar>(i,j) == tonDeCinzaBranco){
                p.x=j;
                p.y=i;
                floodFill(novaImagem,p,novaCorObjeto);
                contadorObjetosSemBuraco++;
            }else if(novaImagem.at<uchar>(i,j) == tonDeCinzaPreto){
                p.x=j;
                p.y=i;
                floodFill(novaImagem,p,novaCorFundo);
                contadorObjetosComBuraco++;
            }
        }
    }

    p.x = 0;
    p.y = 0;
    floodFill(novaImagem,p,tonDeCinzaPreto);

    cout << "Qtd. objetos: " << contadorObjetosSemBuraco << endl;
    cout << "Qtd. objetos sem buraco: " << contadorObjetosSemBuraco - contadorObjetosComBuraco << endl;
    cout << "Qtd. objetos com buraco: " << contadorObjetosComBuraco << endl;

    imshow("bolhas.png", image);

    imwrite("novaImagem.png", novaImagem);
    imshow("Nova Imagem", novaImagem);

    waitKey();
    return 0;
}
----

[[fig_bolhas, bolhas.png]]
//[.text-center]
.Imagem Original
image::images/bolhas.png[Imagem Original, title="Imagem Original"]

[[fig_bolhas_buracos, bolhas2.png]]
//[.text-center]
.Objetos com buracos identificados
image::images/bolhas2.png[Objetos com buracos identificados, title="Objetos com buracos identificados"]


== 4. Manipulação de histogramas

=== 4.1 Equalização do histograma
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios[Ver exercício 5.2.1]

O programa <<exa_equalize>> faz uso da webcam primária do dispositivo em que está sendo executado, a captura dos frames é dado pela classe
VideoCapture. A imagem capturada é então convertida para tons de cinza usando a função cvtColot(Mat, Mat, CV_BGR2GRAY) e essa imagem em tons 
de cinza tem é equalizada fazendo-se uso da função equalizeHist(Mat, Mat), que tem como entrada a imagem a ser equalizada e a imagem, ou elemento 
da classe Mat, que irá armazenar a imagem equalizada. 

link:Projetos/equalize.cpp[Clique aqui] para obter o código do programa.

[[exa_equalize, equalize.cpp]]
[source,cpp]
.Listagem 5: equalize.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  Mat image;
  Mat equalizedImage;
  Mat imageGray;
  int width, height;
  //objeto de captura de frames
  VideoCapture cap;
  //vetor contendo as porcoes r g b da imagem
  vector<Mat> planes;
  //histogramas
  Mat histR, histG, histB;
  //tamanho do vetor histograma
  int nbins = 64;
  //parametros para calculo do histograma
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  cap.open(0);//inicia objeto para captura de imagens

  //testa abertura
  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }

  //le altura e largura do frame sendo capturado
  width  = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

  //mostra altura e largura na tela 
  cout << "largura = " << width << endl;
  cout << "altura  = " << height << endl;

  //define largura e altura do histograma
  int histw = nbins, histh = nbins/2;
  //cria elemento para desenhar os histogramas
  Mat histImgR(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgG(histh, histw, CV_8UC3, Scalar(0,0,0));
  Mat histImgB(histh, histw, CV_8UC3, Scalar(0,0,0));

  while(1){
    cap >> image;//transfere o frama capturado para o elemento tipo Mat
    split (image, planes);//divide os valores r,g e b em elementos diferentes
    //calcula histograma de cada elemento de cor
    calcHist(&planes[0], 1, 0, Mat(), histR, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&planes[1], 1, 0, Mat(), histG, 1,
             &nbins, &histrange,
             uniform, acummulate);
    calcHist(&planes[2], 1, 0, Mat(), histB, 1,
             &nbins, &histrange,
             uniform, acummulate);
    //normaliza os histogramas
    normalize(histR, histR, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
    normalize(histG, histB, 0, histImgR.rows, NORM_MINMAX, -1, Mat());
    normalize(histB, histB, 0, histImgR.rows, NORM_MINMAX, -1, Mat());

    //pinta os elementos dos histogramas todo de preto
    histImgR.setTo(Scalar(0));
    histImgG.setTo(Scalar(0));
    histImgB.setTo(Scalar(0));

    //desenha histograma
    for(int i=0; i<nbins; i++){
      line(histImgR, Point(i, histh),
           Point(i, cvRound(histR.at<float>(i))),
           Scalar(0, 0, 255), 1, 8, 0);
      line(histImgG, Point(i, histh),
           Point(i, cvRound(histG.at<float>(i))),
           Scalar(0, 255, 0), 1, 8, 0);
      line(histImgB, Point(i, histh),
           Point(i, cvRound(histB.at<float>(i))),
           Scalar(255, 0, 0), 1, 8, 0);
    }
    histImgR.copyTo(image(Rect(0, 0       ,nbins, histh)));
    histImgG.copyTo(image(Rect(0, histh   ,nbins, histh)));
    histImgB.copyTo(image(Rect(0, 2*histh ,nbins, histh)));
    imshow("image", image);

    //converte imagem para tons de cinza
    cvtColor(image, imageGray, CV_BGR2GRAY);
    //equaliza a imagem em tons de cinza
    equalizeHist(imageGray, equalizedImage);
    
    imshow("Equalized Gray Image", equalizedImage);

    if(waitKey(27) >= 0) break;
  }
  return 0;
}
----

=== 4.2 Detector de movimentos
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios[Ver exercício 5.2.2]

Assim como o programa <<exa_equalize>>, o <<exa_motion_detector>> faz uso da classe VideoCapture para capturar imagens através de uma webcam
disponível no dispositivo em que está sendo executada. O frame capturado é então convertido de RGB para tons de cinza, e tem seu histograma 
calculado fazendo uso da função calcHist(). O histograma do frame é então armazenada para que possa ser comparado com o histograma do próximo 
frame a ser capturado. A função compareHist() então calcula a differença entre o histograma do frame capturado com o do frame capturado 
anteriormente, caso essa diferença ultrapasse um limiar definido no programa, temos então que houve movimento na região de captura da câmera, 
e um alerta é enviado ao usuário através do terminal.

link:Projetos/motionDetector.cpp[Clique aqui] para obter o código do programa.

[[exa_motion_detector, motionDetector.cpp]]
[source,cpp]
.Listagem 6: motionDetector.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main(int argc, char** argv){
  //matriz para armazenar o quadro capturado
  Mat image;
  int width, height;
  //elemento de captura
  VideoCapture cap;
  //matriz para armezar o histograma do quadro atual e do quadro anterior
  Mat hist, oldHist;
  //entradas para a funcao de calculo do histograma
  int nbins = 64;
  float range[] = {0, 256};
  const float *histrange = { range };
  bool uniform = true;
  bool acummulate = false;

  //abre elemento de captura
  cap.open(0);

  //verifica abertura do elemento de captura
  if(!cap.isOpened()){
    cout << "cameras indisponiveis";
    return -1;
  }
  
  //ler o tamanho do frama sendo capturado
  width  = cap.get(CV_CAP_PROP_FRAME_WIDTH);
  height = cap.get(CV_CAP_PROP_FRAME_HEIGHT);

  cout << "largura = " << width << endl;
  cout << "altura  = " << height << endl;

  int histw = nbins, histh = nbins/2;//calcula largura e altura da imagem do histograma
  Mat histImg(histh, histw, CV_8UC1, Scalar(0));//imagem do histograma, inicialmente toda preta
  int count = 0; //conta o numero da iteracao
  double histDiff = 0; //armezena a differenca entre histogramas

  while(1){   
    //captura a imagem usando a webcam e converte o frame de RGB para GRAYSCALE
    cap >> image;
    cvtColor(image, image, CV_BGR2GRAY);

    //calcula e normaliza o histograma da imagem capturada
    calcHist(&image, 1, 0, Mat(), hist, 1,
             &nbins, &histrange,
             uniform, acummulate);
    normalize(hist, hist, 0, histImg.rows, NORM_MINMAX, -1, Mat());

    //pinta a matriz da imagem do histograma toda de preto
    histImg.setTo(Scalar(0));

    //desenha o histograma 
    for(int i=0; i<nbins; i++){
      line(histImg, Point(i, histh),
           Point(i, cvRound(hist.at<float>(i))),
           Scalar(255), 1, 8, 0);
   }
    
    //adiciona a imagem do histograma a imagem a ser mostrada
    histImg.copyTo(image(Rect(0, 0       ,nbins, histh)));
    imshow("image", image);
    
    //so calcula a diferenca entre os histogramas apartir da segunda captura de quadro
    if(count >=1)
       histDiff = compareHist(hist, oldHist, 0);
    //se houver diferenca de quadro maior que 0.2 escreve na tela o valor retornado pela funcao compareHist()
    if( histDiff < 0.98)
       cout << "motion detected, histDiff = " << histDiff << endl;
    //salva o histograma atual na variavel de histograma antigo para calcular diferencao
    oldHist = hist.clone();
    count++;
    if(waitKey(30) >= 0) break;
  }
  return 0;
}
----


== 5. Filtragem no domínio espacial I

=== 5.1 Filtragem lapplaciano do gaussiano
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_4[Ver exercício 6.2.1]

Para obter o resultado do laplaciano do gaussiano é necessário filtrar a imagem dada com um filtro gaussiano e, logo após, utilizar 
o filtro laplaciano no resultado da filtragem anterior. O resultado desse procedimento pode ser visto na imagem <<fig_laplgauss1>>. Comparando as imagens obtidas depois dos dois processamentos, foi possível observar que, ao realizar somente a filtragem do <<fig_laplaciano>>, a imagem processada apresenta bastante ruído. Já na imagem filtragem com o <<fig_laplgauss1>>, embora tenha havido perda de alguns detalhes, a imagem ficou com muito menos ou quase nenhum ruído.

link:Projetos/laplgauss.cpp[Clique aqui] para obter o código do programa abaixo.

[[exa_laplgauss, laplgauss.cpp]]
[source,cpp]
.Listagem 7: laplgauss.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

void printmask(Mat &m){
  for(int i=0; i<m.size().height; i++){
    for(int j=0; j<m.size().width; j++){
      cout << m.at<float>(i,j) << ",";
    }
    cout << endl;
  }
}

void menu(){
  cout << "\npressione a tecla para ativar o filtro: \n"
	"a - calcular modulo\n"
    "m - media\n"
    "g - gauss\n"
    "v - vertical\n"
	"h - horizontal\n"
    "l - laplaciano\n"
    "x - laplaciano do gaussiano\n"
	"esc - sair\n";
}

int main(int argvc, char** argv){
  VideoCapture video;
  float media[] = {1,1,1,
				   1,1,1,
				   1,1,1};
  float gauss[] = {1,2,1,
				   2,4,2,
				   1,2,1};
  float horizontal[]={-1,0,1,
					  -2,0,2,
					  -1,0,1};
  float vertical[]={-1,-2,-1,
					0,0,0,
					1,2,1};
  float laplacian[]={0,-1,0,
					 -1,4,-1,
					 0,-1,0};

  Mat cap, frame, frame32f, frameFiltered, frameFiltered1;
  Mat mask(3,3,CV_32F), mask1;
  Mat result, result1;
  double width, height;
  int absolut;
  char key;
  bool laplgauss = false;

  video.open(0);
  if(!video.isOpened())
    return -1;

  width=video.get(CV_CAP_PROP_FRAME_WIDTH);
  height=video.get(CV_CAP_PROP_FRAME_HEIGHT);

  std::cout << "largura=" << width << "\n";;
  std::cout << "altura =" << height<< "\n";;

  namedWindow("filtroespacial",1);

  mask = Mat(3, 3, CV_32F, media);
  scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
  swap(mask, mask1);
  absolut=1;

  menu();
  for(;;){
    video >> cap;
    cvtColor(cap, frame, CV_BGR2GRAY);
    flip(frame, frame, 1);
    imshow("original", frame);
    frame.convertTo(frame32f, CV_32F);

    if(laplgauss){
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);
      mask = Mat(3, 3, CV_32F, laplacian);
      filter2D(frameFiltered, frameFiltered1, frameFiltered.depth(), mask, Point(1,1), 0);

      if(absolut){
        frameFiltered1=abs(frameFiltered1);
      }

      frameFiltered1.convertTo(result1, CV_8U);
      imshow("filtroespacial", result1);
    }
    else{
      filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1,1), 0);

      if(absolut){
        frameFiltered=abs(frameFiltered);
      }

      frameFiltered.convertTo(result, CV_8U);
      imshow("filtroespacial", result);
    }

    key = (char) waitKey(10);
    if( key == 27 ) break; // esc pressed!
    switch(key){
    case 'a':
    laplgauss = false;
      menu();
      absolut=!absolut;
      break;
    case 'm':
      menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1/9.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      laplgauss = false;
      
      break;
    case 'g':
      menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1/16.0, Mat::zeros(3,3,CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      laplgauss = false;
      
      break;
    case 'h':
      menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      laplgauss = false;

      break;
    case 'v':
      menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      laplgauss = false;

      break;
    case 'l':
      menu();
      mask = Mat(3, 3, CV_32F, laplacian);
      printmask(mask);
      laplgauss = false;

      break;
    case 'x':
     laplgauss = true;
     menu();

     break;
    default:
      break;
    }
  }
  return 0;
}
----

[[fig_laplgauss, imagem original]]
//[.text-center]
.Imagem original
image::images/laplgauss.jpg[Imagem original, title="Imagem original"]

[[fig_laplaciano, laplaciano]]
//[.text-center]
.Imagem processada com filtro laplaciano
image::images/laplgauss_2.jpg[Imagem processada com filtro laplaciano, title="Imagem processada com filtro laplaciano"]

[[fig_laplgauss1, laplgauss]]
//[.text-center]
.Imagem processada com filtro laplgauss
image::images/laplgauss_1.jpg[Imagem processada com filtro laplgauss, title="Imagem processada com filtro laplgauss"]


== 6. Filtragem no domínio espacial II

=== 6.1 Implementação do tiltshift em imagem
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios[Ver exercício 7.2.1]

=== 6.2 Implementação do tiltshift em vídeo
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios[Ver exercício 7.2.2]


== 7. Filtragem no Domínio da Frequência

=== 7.1 Filtro Homomórfico
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_6[Ver exercício 8.2]

O exercício proposto consiste em realizar a filtragem de uma imagem para atenuar efeitos de iluminação irregular. Para tal, foi realizada uma filtragem no domínio da frequência utilizando um filtro homomórfico descrito pela equação abaixo.

stem:[H(u,v) = (\gamma_h - \gamma_l)(1 - e^{-c\frac{D^2_{uv}}{D^2_0}}) + \gamma_l]

Primeiramente, para que seja realizada uma filtragem no domínio da frequência, a imagem a ser filtrada deve estar nesse domínio, e para tal usou-se a DFT. O primeiro passo para realizar a operação do DFT é redimensionar a imagem para um tamanho ótimo e criar uma matriz de dois canais contendo a parte real e imaginária da imagem. Esse procedimento é realizado pela função preparaDFT() que pode ser vista abaixo.

[[app-listing]]
[source, cpp]
.Listagem 8: preparaDFT()
----
void preparaDFT(Mat img, Mat& complexImg, bool print = false){
    //calcula tamanho ideal para o calcula da DFT
    int M = getOptimalDFTSize(img.rows);
    int N = getOptimalDFTSize(img.cols);

    Mat paddedImg;
    Mat_<float> realInput, zeros;
    //aumenta a imagem para o tamanho ideal
    copyMakeBorder(img, paddedImg, 0, M - img.rows, 0, N - img.cols, BORDER_CONSTANT, Scalar::all(0));
    //imprime a imagem redimensionada caso solicitado
    if(print)
    imshow("Imagem Redimensionada", paddedImg);
    //inicializa uma matriz de zeros (parte imaginaria)
    zeros = Mat_<float>::zeros(paddedImg.size());
    complexImg = Mat(paddedImg.size(), CV_32FC2, Scalar(0));
    //converte a parte real da imagem para float
    realInput = Mat_<float>(paddedImg);
    //junta parte real e imaginaria em uma matriz de dois canais
    vector<Mat> planos;
    planos.push_back(realInput);
    planos.push_back(zeros);
    merge(planos, complexImg);
}
----

O próximo passo é calcular a DFT da imagem e preparar para a filtragem, reorganizando o espectro. Essa operação é realizada pela função calculaDFT() que tem como entrada a matriz da imagem e uma variavel booleana que habilita mostrar a imagem no espectro para o usuário.

[[app-listing]]
[source, cpp]
.Listagem 9: calculaDFT()
----
void calculaDFT(Mat complexImg, bool print = false){
    //calcula o dft da imagem
    dft(complexImg, complexImg);
    //reorganiza o espectro
    deslocaDFT(complexImg);
    //imprime o espectro caso solicitado
    if(print){
        vector<Mat> planos;
        split(complexImg, planos);
        //normalize(planos[0], planos[0], 0, 1, CV_MINMAX);
        imshow("Espectro da Imagem", planos[1]);
    }
}
----

A funcão geraFiltroHomomorfico() é usada para criar um matriz de dois canais contendo o filtro homomórfico conforme descrito na equação. Esta função tem como entradas: a matriz da imagem complexa, a matriz onde será armazenado o filtro, stem:[\gamma_h], stem:[\gamma_l], stem:[D_0], stem:[c] e um valor booleano que irá mostrar a imagem do filtro caso true seja passado.

[[app-listing]]
[source, cpp]
.Listagem 10: geraFiltroHomomorfico()
----
void geraFiltroHomomorfico(Mat complexImg, Mat& filtro, float gamaH, float gamaL, float raio, float var, bool print = false){
    vector<Mat> planos;
    //separa os canais da matriz da imagem complexa
    split(complexImg, planos);

    Mat img = planos[0];
    //cria matriz temporaria de mesmo tamanho da matriz da imagem
    Mat tmp;
    tmp = Mat(img.size(), CV_32F, Scalar(0));

    int M = tmp.rows;
    int N = tmp.cols;
    //preenche a matriz temporaria com o filtro
    for (int i = 0; i < M; i++) {
        for (int j = 0; j < N; j++) {
            float Duv = (i - M/2)*(i - M/2)+(j - N/2)*(j - N/2);
            Duv = sqrt(Duv);
            float pot = -var*((Duv*Duv)/(raio*raio));
            tmp.at<float>(i,j) = (gamaH - gamaL)*(1-exp(pot)) + gamaL;
        }
    }

    filtro = Mat(img.size(), CV_32FC2, Scalar(0));
    //cria uma matriz de filtro com dois canais iguais
    planos.clear();
    planos.push_back(tmp);
    planos.push_back(tmp);
    merge(planos, filtro);
    //imprime o filtro caso solicitado
    if(print)
    imshow("filtro homomorfico", tmp);

}
----

Uma vez que a imagem já foi transfomada para o domínio da frequência e o filtro a ser usado já foi gerado, pode-se então realizar a operação de filtragem. Usa-se, então, a função mulSpectrums() disponível na biblioteca do openCV.

O último passo é realizar a transformada inversa para que a imagem retorne ao domínio original. A função calculaDFTInversa() é usada para reorganizar o espectro, realizar a transformada inversa, separar os canais e retornar a parte real da imagem.

[[app-listing]]
[source, cpp]
.Listagem 11: calculaDFTInversa()
----
void calculaDFTInverso(Mat complexImg, Mat& imgFiltrada, Mat imgOriginal){
    //reorganiza o espectro
    deslocaDFT(complexImg);

    //calcula DFT inversa
    idft(complexImg, complexImg);

    //separa os canais
    vector<Mat> planos;
    split(complexImg, planos);

    //normaliza a imagem para valores float entre 0 e 1
    normalize(planos[0], planos[0], 0, 1, CV_MINMAX);
    imgFiltrada = planos[0];
    /*
    //redimensiona a imagem para o tamanho da imagem original
    if(imgOriginal.cols == planos[0].cols && imgOriginal.rows == planos[0].rows)
        imgFiltrada = planos[0];
    else
        Mat(planos[0], Rect(0,0,imgOriginal.rows-1, imgOriginal.cols-1)).copyTo(imgFiltrada);
    */
}
----

A função main() do programa de filtragem pode ser visto abaixo. Como podemos observar, após preparada para realização da DFT, a matriz complexa da imagem sofre um operação logarítmica com seu valor adicionado de 1 para evitar problema de indefinição da função logaritmo. Além disso, após a realização da DFT inversa, a parte real da imagem filtrada passa pela função exponencial e tem seus valores normalizados entre 0 e 1. Esses dois passos descritos acima também fazem parte do algoritmo de filtragem homomórfica.

[[app-listing]]
[source, cpp]
.Listagem 12: main()
----
int main(int, char** argv){
    Mat img, complexImage, filtro, imgFiltrada;
    char key;

    img = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
    if(!img.data)
        cout << "erro ao tentar abrir a imagem " << argv[1] << endl;

    namedWindow("Imagem Original", 1);

    sprintf( TrackbarName, "Gamma H: ");
    createTrackbar( TrackbarName, "Imagem Original",
    &gammaH_slider,
    gammaH_slider_max,
    on_trackbar_gammaH );
    on_trackbar_gammaH(gammaH_slider, 0 );

    sprintf( TrackbarName, "Gamma L: ");
    createTrackbar( TrackbarName, "Imagem Original",
    &gammaL_slider,
    gammaL_slider_max,
    on_trackbar_gammaL );
    on_trackbar_gammaL(gammaL_slider, 0 );

    sprintf( TrackbarName, "C: ");
    createTrackbar( TrackbarName, "Imagem Original",
    &c_slider,
    c_slider_max,
    on_trackbar_c );
    on_trackbar_c(c_slider, 0 );

    sprintf( TrackbarName, "D0: ");
    createTrackbar( TrackbarName, "Imagem Original",
    &D0_slider,
    D0_slider_max,
    on_trackbar_D0 );
    on_trackbar_D0(D0_slider, 0 );

    imshow("Imagem Original", img);

    for (;;) {

        preparaDFT(img, complexImage);

        log(complexImage+1, complexImage);

        calculaDFT(complexImage);

        geraFiltroHomomorfico(complexImage, filtro, gammaH, gammaL, D0, c, true);

        // aplica o filtro frequencial
        mulSpectrums(complexImage, filtro, complexImage, 0);

        calculaDFTInverso(complexImage, imgFiltrada, img);

        exp(imgFiltrada, imgFiltrada);
        normalize(imgFiltrada, imgFiltrada, 0, 1, CV_MINMAX);

        imshow("Imagem Filtrada", imgFiltrada);

        key = (char) waitKey(10);
        if (key == 27) {
            break;
        }
    }

    return 0;
}
----

Para a validação do algoritmo implementado foi usada a imagem com problema de iluminação irregular abaixo.

[[imgOriginal, homomorfica.png]]
//[.text-center]
.Imagem Original
image::images/homomorfica.png[title = "Imagem Original", width = "256", height = "256"]

Os parâmetros usados para o filtro homomórfico foram stem:[\gamma_h = 50], stem:[\gamma_l = 30], stem:[D_0 = 30] e stem:[c = 40]. O resultado do processo de filtragem pode ser conferido abaixo.

[[imgfiltrada, imgFiltrada.png]]
//[.text-center]
.Imagem Filtrada
image::images/ImgFiltrada.png[title = "Imagem Filtrada", width = "256", height = "256"]

O aquivo completo pode ser baixado link:Projetos/filtroHomomorfico.cpp[aqui].


== 8. Canny e a Arte com Pontilhismo
link:http://agostinhobritojr.github.io/tutoriais/pdi/#_exerc%C3%ADcios_7[Ver exercício 11.1]

O código criado para este exercíco é uma composição do algorítmo do filtro de Canny e do filtro do pontilhismo que estão na página da disciplina. Para a realização do processo, inicialmente aplicamos o filtro do pontilhismo na imagem. Depois fizemos um for para passar 4 vezes o filtro de canny na imagem. Para cada uma das iterações alteramos o limiar do filtro com a inteção de obter, a cada iteração, uma imagem filtrada com menos bordas. A cada iteração, a imagem filtrada era percorrida pixel a pixel e, caso hovesse um pixel com ton de cinza maior que zero, era desenhado um círculo na imagem filtrada com pontilhismo na mesma coordenada desse pixel. Dessa forma, as bordas tornavam-se mais destacadas. O código é mostrado abaixo.

[[exa_cannypoints, cannypoints.cpp]]
[source,cpp]
.Listagem 13: cannypoints.cpp
----
#include <iostream>
#include <opencv2/opencv.hpp>
#include <fstream>
#include <iomanip>
#include <vector>
#include <algorithm>
#include <numeric>
#include <ctime>
#include <cstdlib>

using namespace std;
using namespace cv;

#define STEP 5
#define JITTER 3
#define RAIO 5

int main(int argc, char** argv){
  vector<int> yrange;
  vector<int> xrange;

  Mat imagemOriginal, borderImagemOriginal;
  Mat imagemComPontilhismo;
  int width, height;
  int gray;
  int x, y;

  imagemOriginal= imread(argv[1],CV_LOAD_IMAGE_GRAYSCALE);

  srand(time(0));

  if(!imagemOriginal.data){
      cout << "nao abriu" << argv[1] << endl;
    cout << argv[0] << " imagemOriginal.jpg";
    exit(0);
  }

  width = imagemOriginal.size().width;
  height = imagemOriginal.size().height;

  xrange.resize(height/STEP);
  yrange.resize(width/STEP);

  iota(xrange.begin(), xrange.end(), 0);
  iota(yrange.begin(), yrange.end(), 0);

  for(uint i=0; i<xrange.size(); i++){
    xrange[i]= xrange[i]*STEP+STEP/2;
    yrange[i]= yrange[i]*STEP+STEP/2;
  }

  imagemOriginal.copyTo(imagemComPontilhismo);
  random_shuffle(xrange.begin(), xrange.end());

  for(auto i : xrange){
    random_shuffle(yrange.begin(), yrange.end());
    for(auto j : yrange){
      x = i+rand()%(2*JITTER)-JITTER+1;
      y = j+rand()%(2*JITTER)-JITTER+1;
      gray = imagemOriginal.at<uchar>(x,y);
      circle(imagemComPontilhismo,
             cv::Point(y,x),
             RAIO,
             CV_RGB(gray,gray,gray),
             -1,
             CV_AA);
    }
  }

  imshow("Imagem com Pontilhismo", imagemComPontilhismo);
  imwrite("imgfiltroPontilhismo.jpg", imagemComPontilhismo);

  for(int it=0; it<5; it++){
     Canny(imagemOriginal, borderImagemOriginal, 10*it, 50*it);
     int raio = 5-it;

     for(int i=0; i<height; i++ ){
        for(int j=0; j<width; j++){
           if(borderImagemOriginal.at<uchar>(i,j)>0){
              gray = imagemOriginal.at<uchar>(i,j);
              circle(imagemComPontilhismo,
                     cv::Point(j,i),
                     raio,
                     CV_RGB(gray,gray,gray),
                     -1,
                     CV_AA);
           }
        }
     }
  }

  imshow("Imagem com CannyPoints", imagemComPontilhismo);
  imwrite("imgfiltroCannyPoints.jpg", imagemComPontilhismo);

  waitKey();
  return 0;
}
----

A imagem abaixo foi dada como entrada para o programa.

[[imgOriginalLena, imgOriginalLena.png]]
//[.text-center]
.Imagem Original
image::images/imgOriginalLena.png[title = "Imagem Original"]

O resultado da imagem <<imgOriginalLena>> com o filtro pontilhismo é exibido na imagem <<imgFiltroPontilhismo>>.

[[imgFiltroPontilhismo, imgFiltroPontilhismo.jpg]]
//[.text-center]
.Imagem com Pontilhismo
image::images/imgFiltroPontilhismo.jpg[title = "Imagem com Pontilhismo"]

O resultado da aplicação do filtro CannyPoints na imagem <<imgOriginalLena>> é vista na imagem <<imgFiltroCannyPoints>>.

[[imgFiltroCannyPoints, imgFiltroCannyPoints.jpg]]
//[.text-center]
.Imagem com CannyPoints
image::images/imgFiltroCannyPoints.jpg[title = "Imagem com CannyPoints"]

O código do programa pode ser obtido link:Projetos/cannypoints.cpp[aqui].
